{"cells":[{"cell_type":"markdown","metadata":{"id":"f6lTqF-Kf1RW"},"source":["# Model Pipeline\n","\n","`roboflow` : 객체 탐지 -> `predict2crop()` : 이미지 크롭 -> `CLOVA_api()`: OCR_api -> 텍스트 추출"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16471,"status":"ok","timestamp":1705305537131,"user":{"displayName":"김정연","userId":"15493487167599861874"},"user_tz":-540},"id":"R07ffrZtwkA4","outputId":"95fd235f-7a7e-4b85-f005-419a4ba114c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"eSdG0ksy1eqF"},"source":["- packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZAuwNHn1df5"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision.datasets import CIFAR10\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import platform\n","from PIL import ImageFont, ImageDraw, Image\n","from matplotlib import pyplot as plt\n","import requests\n","import base64\n","import uuid\n","import json\n","import time\n","import cv2\n","import requests\n","import platform\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import os"]},{"cell_type":"markdown","metadata":{"id":"uTPujsC1hIwo"},"source":["## 데이터 경로지정\n","\n","> 해당 파일은 다량의 이미지를 Object Detection 모델과 OCR 모델에 넣어봄으로 오류가 없는지 테스트하는 용도입니다.\n","\n","- `image_folder` : 데이터가 있는 폴더 경로"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dl-UwWRcbSOr"},"outputs":[],"source":["image_folder = '/content/drive/MyDrive/Datas/train/' # 데이터가 존재하는 폴더 경로\n","files = os.listdir(image_folder)\n","image_files = [file for file in files] # 데이터 접근 : 다중 파일로 테스트 시, 파일 순회"]},{"cell_type":"markdown","metadata":{"id":"Gyd9OvJyggH-"},"source":["## Modules\n","\n","> 이미지에 대한 입력 -> 객체 탐지 -> OCR -> 텍스트 전처리\n","\n","- 해당 과정에 필요한 모듈들 입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lks81O_Bf93d"},"outputs":[],"source":["def CLOVA_api(secret_key, api_url, image : np.array):\n","    \"\"\"\n","    Usage : CLOVA api 호출\n","\n","    Parameters\n","    ----------\n","    secret_key : api key\n","    api_url : api_url\n","    image : 크롭된 image\n","\n","    Returns\n","    -------\n","\n","    response : api 호출 결과 (ex. 200,400,404, ...)\n","\n","    \"\"\"\n","    # Convert np.ndarray to bytes\n","    if image is not None:\n","        _, buffer = cv2.imencode('.jpg', image)\n","        file_data = buffer.tobytes()\n","\n","    request_json = {\n","        'images': [\n","            {\n","                'format': 'jpg',\n","                'name': 'demo',\n","                'data': base64.b64encode(file_data).decode()\n","                #'url': image_url\n","            }\n","        ],\n","        'requestId': str(uuid.uuid4()),\n","        'version': 'V2',\n","        'timestamp': int(round(time.time() * 1000))\n","    }\n","    payload = json.dumps(request_json).encode('UTF-8')\n","    headers = {\n","      'X-OCR-SECRET': secret_key,\n","      'Content-Type': 'application/json'\n","    }\n","    response = requests.request(\"POST\", api_url, headers=headers, data = payload)\n","\n","    return response\n","\n","\n","\n","\n","def imageOCR(response, img : np.array):\n","    \"\"\"\n","    Usage : api 적용 결과 (OCR 결과) 시각화\n","\n","    Parameters\n","    ----------\n","    response : api 호출 결과\n","    img : 크롭된 이미지\n","\n","    Returns\n","    -------\n","    temp : 추출된 text\n","    image : 크롭된 이미지 내 OCR 적용 결과\n","\n","    \"\"\"\n","    try : result = response.json()\n","    except :\n","        print(response, 'AttributeError: Responsed \\'int\\' object' )\n","\n","    with open('result.json', 'w', encoding='utf-8') as make_file:\n","        json.dump(result, make_file, indent=\"\\t\", ensure_ascii=False)\n","\n","    # Error 처리\n","    try : print(result['images'][0]['message'])\n","    except : return None, None\n","\n","    # respone.json()에서 띄어쓰기 처리\n","    texts = connectWord(result)\n","\n","\n","    # 이미지 시각화\n","    bBs = [b['boundingPoly'] for b in result['images'][0]['fields']]\n","\n","    # bounding box 표시\n","    for box in bBs:\n","        vertices = np.array([(int(point['x']), int(point['y'])) for point in box['vertices']], np.int32)\n","        vertices = vertices.reshape((-1, 1, 2))\n","        img = cv2.polylines(img, [vertices], isClosed=True, color=(255, 0, 0), thickness=2)\n","\n","    # 이미지 보여주기\n","    cv2_imshow(img) # only colab\n","    # print(text)\n","\n","    return texts, img\n","\n","\n","def textPreprocessing(input_str : str):\n","    \"\"\"\n","    Usage : OCR 박스 별로 텍스트 전처리 적용\n","\n","    Parameters\n","    ----------\n","    response : api 호출 결과\n","    img : 크롭된 이미지\n","\n","    Returns\n","    -------\n","    temp : 추출된 text\n","    image : 크롭된 이미지 내 OCR 적용 결과\n","\n","    \"\"\"\n","    import re\n","    # print(input_str)\n","\n","    pt1 = re.compile(r'[\\s@#$%^&*()_+{}\\[\\]:;<>.?\\/|`~-]') # 특수 기호 처리\n","    pt2 = re.compile(r'(\\d+)\\s*([gGmMlL당]+)') # 10g당과 같은 무게 단위 처리\n","    # pt3 = re.compile(r'(\\d+)\\s*([원]+)') # 780원과 같은 무게별 가격 처리\n","    pt3 = re.compile(r'(\\d+)\\s*([개입]+)') # 10개와 같은 개수 단위 처리\n","    result_str = pt1.sub('', input_str)\n","    result_str = pt2.sub(' ', result_str)\n","    result_str = pt3.sub(' ', result_str)\n","    # result_str = pt4.sub(' ', result_str)\n","    # print(result_str)\n","\n","    return result_str\n","\n","\n","\n","def connectWord(ocr_json):\n","    \"\"\"\n","    Usage : OCR 결과 내 띄어쓰기 처리\n","\n","    Parameters\n","    ----------\n","    ocr_json : api 호출 결과\n","\n","    Returns -> str\n","    -------\n","    detected_texts : 최종 결과\n","\n","    \"\"\"\n","    detected_texts = ''\n","\n","    # 필드 정보 추출\n","    fields = ocr_json['images'][0].get('fields', [])\n","\n","    # 각 필드에 대해 y좌표 계산\n","    word_list = []\n","    for field in fields:\n","        bounding_poly = field.get('boundingPoly')\n","        infer_text = field.get('inferText')\n","\n","        if bounding_poly and infer_text:\n","            vertices = bounding_poly['vertices']\n","\n","            left_y_coord = vertices[0]['y']  # 첫 번째 꼭짓점의 y좌표를 사용\n","            right_y_coord = vertices[1]['y']\n","            word = infer_text\n","            word_list.append({'word': word, 'left_y': left_y_coord, 'right_y':right_y_coord})\n","\n","    # y좌표가 유사한 단어를 그룹화\n","    grouped_words = []\n","    if word_list:  # word_list가 비어있지 않은 경우에만 처리\n","        current_group = [word_list[0]]\n","\n","        for i in range(1, len(word_list)):\n","            if abs(word_list[i]['left_y'] - word_list[i-1]['right_y']) < 5:\n","                current_group.append(word_list[i])\n","            else:\n","                grouped_words.append(current_group)\n","                current_group = [word_list[i]]\n","\n","        if current_group:\n","            grouped_words.append(current_group)\n","\n","    for group in grouped_words:\n","\n","        # 그룹 내의 단어들을 하나의 문자열로 합침\n","        group = list(map(lambda word_info : textPreprocessing(word_info['word']), group))\n","\n","        # 문자열이 정수로만 이루어져 있지 않은 경우에만 추가\n","        group_text = ' '.join([word for word in group if not word.isdigit()])\n","        print(group_text)\n","        # if not group_text.isdigit():\n","\n","        detected_texts += group_text\n","        detected_texts += '\\t'\n","\n","    return detected_texts\n","\n","\n","\n","def modelPredict(model, input_Data):\n","    try : predictions_data = model.predict(input_Data, confidence=50, overlap=50).json()\n","    except :\n","        print('Predict Error')\n","        return None\n","    # image_path = predictions_data['predictions'][0]['image_path']  # Assuming all predictions have the same image path\n","\n","    return predictions_data\n","\n","\n","\n","def predict2crop(model, folder_path, image_file, resize = 256):\n","    \"\"\"\n","    Usage : 객체 탐지 및 원본 및 크롭 이미지 return\n","\n","    Parameters\n","    ----------\n","    model : Object Detection Model\n","    folder_path : 데이터 폴더 경로\n","    image_file : 데이터 파일 경로\n","\n","    Returns : (original_image, cropped_image)\n","    -------\n","    type : tuple\n","    original_image : 원본 이미지\n","    cropped_image : 크롭된 이미지\n","\n","    \"\"\"\n","    image_path = folder_path + image_file\n","    img_size = resize # img_size * img_size\n","\n","    org_img = cv2.imread(image_path)\n","    if org_img is None:\n","        print(f\"Error: Unable to read the image file {image_path}\")\n","        return None, None\n","\n","    rsz_img = cv2.resize(org_img, (img_size, img_size), interpolation= cv2.INTER_AREA)\n","    adc_img = auto_adjust_contrast(rsz_img)\n","\n","\n","    predictions_data = modelPredict(model, input_Data = adc_img) # resize된 img속에서 찾은 bbox 좌표\n","\n","    print('Detected Obj : ', len(predictions_data['predictions']))\n","\n","    if predictions_data is None :\n","        print('Detect Nothing. It\\'s Too Close')\n","        return org_img, org_img\n","\n","    if len(predictions_data['predictions']) > 1:\n","        print('! Error : Multiple detection Error. Take more closer')\n","        return None, None\n","\n","    orgBBcoor = predBBcoor(org_img, predictions_data)\n","    cropped_img = imgCrop(org_img, orgBBcoor) #원본이미지에서 crop\n","\n","    return org_img, cropped_img\n","\n","\n","\n","def imgCrop(img, bbCoor):\n","    \"\"\"\n","    Usage : resize된 이미지에서의 바운딩 박스 좌표를 원본 이미지의 바운딩 박스 좌표로 변환\n","\n","    Parameters\n","    ----------\n","    img : 원본 이미지(no resize)\n","    bbCoor : (x, y, width, height) -> 원본 이미지에서의 bbox 좌표\n","\n","    Returns : np.array\n","    -------\n","    cropped_img\n","\n","    \"\"\"\n","    if None in bbCoor : return img\n","\n","    x, y, width, height = bbCoor # real coordinate\n","\n","    half_w, half_h = round(width/2), round(height/2)\n","\n","    cropped_img = img[abs(y-half_h) : y+half_h, abs(x-half_w ): x+half_w] # img crop\n","\n","    # # 결과 시각화\n","    # cv2.rectangle(img, (x - half_w, y - half_h), (x + half_w, y + half_h), (0, 255, 0), 2)\n","    # print('\\n Original')\n","    # cv2_imshow(img) # only colab\n","    # print('\\n Cropped')\n","    # cv2_imshow(cropped_img) # only colab\n","\n","    return cropped_img\n","\n","\n","\n","def predBBcoor(org_img : np.array, pred_data : list, resize=256):\n","    \"\"\"\n","    Usage : resize된 이미지에서의 바운딩 박스 좌표를 원본 이미지의 바운딩 박스 좌표로 변환\n","\n","    Parameters\n","    ----------\n","    org_img : 원본 이미지(no resize)\n","    pred_data : list\n","\n","    Returns : tuple\n","    -------\n","    x, y, width, height\n","\n","    \"\"\"\n","    try : prediction = pred_data['predictions'][0] # dict\n","    except : return None, None, None, None # 탐지 되지 않을 시\n","\n","    # resized bbox coordinate\n","    rx, ry, rwidth, rheight = int(prediction['x']), int(prediction['y']), int(prediction['width']), int(prediction['height'])\n","    half_w, half_h = round(rwidth/2), round(rheight/2)\n","\n","    # real h, w\n","    h, w, _ = org_img.shape\n","    # real bbox coordinate\n","    x, y, width, height = round((w*rx)/resize), round((h*ry)/resize), round((rwidth*w)/256), round((rheight*h)/256)\n","\n","    return x, y, width, height\n","\n","\n","\n","# preprocessing : auto_adjust_contrast\n","def auto_adjust_contrast(image : np.array):\n","    # Flatten the image to 1D array\n","    try : flat_image = image.flatten()\n","    except : return None\n","\n","    # Compute the histogram\n","    histogram, bins = np.histogram(flat_image, bins=256, range=(0, 256))\n","\n","    # Compute the cumulative distribution function (CDF)\n","    cdf = histogram.cumsum()\n","\n","    # Normalize the CDF\n","    cdf_normalized = cdf / cdf.max()\n","\n","    # Perform histogram equalization\n","    equalized_image = np.interp(flat_image, bins[:-1], cdf_normalized * 255).reshape(image.shape)\n","\n","    return equalized_image.astype(np.uint8) # np.array"]},{"cell_type":"markdown","metadata":{"id":"2GvOMjO42J2a"},"source":["- model load"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14731,"status":"ok","timestamp":1705305584946,"user":{"displayName":"김정연","userId":"15493487167599861874"},"user_tz":-540},"id":"0GV062V02JOb","outputId":"910f6883-ad63-4cd6-f3af-77438735eb25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting roboflow\n","  Downloading roboflow-1.1.16-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Collecting supervision (from roboflow)\n","  Downloading supervision-0.17.1-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.47.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n","Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.9.0.80\n","    Uninstalling opencv-python-headless-4.9.0.80:\n","      Successfully uninstalled opencv-python-headless-4.9.0.80\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.12.1\n","    Uninstalling cycler-0.12.1:\n","      Successfully uninstalled cycler-0.12.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2023.11.17\n","    Uninstalling certifi-2023.11.17:\n","      Successfully uninstalled certifi-2023.11.17\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.16 supervision-0.17.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","chardet","cv2","cycler","idna"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"data":{"text/plain":["<roboflow.models.object_detection.ObjectDetectionModel at 0x789fa8cb2e60>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["!pip install roboflow\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"eyKD4VJQ4nRqtosRytMg\")\n","project = rf.workspace().project(\"price-tag-dxlmv\")\n","model = project.version(15).model\n","\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"16pNf3a9JqY43-RO51zm6W3PxCOGmMya4"},"executionInfo":{"elapsed":776565,"status":"ok","timestamp":1705311883448,"user":{"displayName":"김정연","userId":"15493487167599861874"},"user_tz":-540},"id":"rn8r07QaiJ3V","outputId":"dd91193f-52ea-4725-a2b6-a46c28c64591"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# OCR api\n","secret_key = \"Y0l6ZHF1Um9CSWp3aHpJU3JDeFdpUGp1cG16T3hFQkg=\"\n","api_url = 'https://p0fsnflvaw.apigw.ntruss.com/custom/v1/27259/8a921c4c7d4e552c974b102e64c6227f3a2995ca938c066ddeb1442d6bf4b67c/general'\n","\n","detections = []\n","\n","# 단일 메세지 넣을 시\n","# if image:\n","total_len = len(image_files)\n","cnt = 1\n","\n","for image in image_files: # 다량의 이미지 테스트 용\n","    original_img, cropped_img = predict2crop(model, folder_path = image_folder ,image_file = image)\n","    print(f'process : {(cnt/total_len*100) : .2f}%')\n","    cnt += 1\n","\n","    if cropped_img is None : continue\n","\n","    # cropped_img = cv2.resize(cropped_img,(128,64)) # 필수\n","\n","    response = CLOVA_api(secret_key ,api_url ,image = cropped_img)\n","    texts, img = imageOCR(response, img = cropped_img)\n","\n","    print(texts)\n","\n","    detections.append(texts)\n"]},{"cell_type":"markdown","metadata":{"id":"qkNm0E00aDrF"},"source":["## text preprocessing Example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBoy57YCaDEE"},"outputs":[],"source":["def remove_pattern(input_string):\n","    # Define a regex pattern to match amounts in the range of 1,000 to KRW\n","    pattern = r'\\b\\d{1,3}(,\\d{3})*(?:\\.\\d{1,2})?\\s*(?:원|\\)\\b'\n","\n","    # Use re.sub to replace matches with an empty string\n","    cleaned_string = re.sub(pattern, '', input_string)\n","\n","    return cleaned_string\n","\n","# Example usage:\n","input_str = 'Gyro Drop 100ml당 1000원 ticeiq'\n","result = remove_pattern(input_str)\n","result"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"l9aE2_VoXy55","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705312078655,"user_tz":-540,"elapsed":337,"user":{"displayName":"김정연","userId":"15493487167599861874"}},"outputId":"d922f6fc-0ec9-4822-b732-dba88b1a1bbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["경주1642블랑   cfcgfx\n","greatforyou  기타등등 알지모르겟지 weknxpcpe\n","mealMeaL  일지라도?\n"]}],"source":["import re\n","\n","def extract_grams(input_string):\n","    # Define a regex pattern to find numeric values followed by 'g'\n","    pt1 = re.compile(r'(\\d+)\\s*([gGmMlL당]+)')\n","    pt2 = re.compile(r'(\\d+)\\s*([원]+)')\n","    pt3 = re.compile(r'(\\d+)\\s*([개입]+)')\n","\n","    # Use re.findall to find all matches in the input string\n","    matches = pt1.sub(' ',input_string)#re.sub(pt1, ' ',input_string, )\n","    matches = pt2.sub(' ', matches) # re.sub(pt2, ' ',matches)\n","    matches = pt3.sub(' ', matches)\n","    return matches\n","\n","# Example usage:\n","input_str1 = '경주1642블랑123410g523992입1234개cfcgfx'\n","input_str2 = 'greatforyou100g당1424원기타등등 알지모르겟지 weknxpcpe'\n","input_str3 = 'mealMeaL100ml당1423원일지라도?'\n","\n","\n","result1 = extract_grams(input_str1)\n","result2 = extract_grams(input_str2)\n","result3 = extract_grams(input_str3)\n","\n","print(result1)  # Output: ['10']\n","print(result2)  # Output: ['100']\n","print(result3)  # Output: []"]},{"cell_type":"markdown","metadata":{"id":"_-gk4kGHaI9t"},"source":["## save Result"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":303,"status":"ok","timestamp":1705312111441,"user":{"displayName":"김정연","userId":"15493487167599861874"},"user_tz":-540},"id":"NVL-rLM4PYYX"},"outputs":[],"source":["file_path = '/content/detectedV3.txt'\n","\n","with open(file_path, 'w') as file :\n","    for s in detections:\n","        file.write(s + '\\n')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"5vhx06UY5L_x","outputId":"dd27ca95-e939-44eb-8402-a76a8127f7b3"},"outputs":[{"ename":"NameError","evalue":"name 'detections' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2482fcd82f01>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'detections' is not defined"]}],"source":["text = ''\n","for t in detections:\n","    if t == '': continue\n","    text += t\n","    text += '\\n'\n","print(text)"]},{"cell_type":"markdown","metadata":{"id":"awIQML7YPB2w"},"source":["- Text save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkx7ls0NPAVK"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"qfq6hEcrbSqO"},"source":["## Text preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"v445tbh48eeR","outputId":"c1de1449-46d2-4546-fcf1-19b6da398c49"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'일반냉장고 R-B432GCWP.AKOR LG전자 나노참숯탈취 크기(WxHxD) 멀티냉각방식 755x1777x707 특급냉장 Bar 핸들타입'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["' '.join(texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPfNtUsp8jBu","outputId":"2ed1d3c8-47e9-4620-dcf6-593955093932"},"outputs":[{"name":"stdout","output_type":"stream","text":["adidas SOLAR RIDE M CE449\n","주간추천상품 신라면멀티팩120g*5 2,490원\n","성동명 (원전시) 포장 년,월,일 두층 년,월,일 100g(원)중량(g) 100 10 가격(원) 1000 BARCORE DTHER\n","3238 553568 123 10 1/2 1285cvml ### 28S ### DEVALUAL 86585558 ### 400 Mid NO\n","삼성 갤럭시 ZFLIP SM-F700NZPAAKOO (0) 자급제폰 1,650,000 1,649,980 기준요금제: 자급제폰 24개월기준 출고가 통신사 지원금 아이마트 지원금 1,650,000 10 10 화면크기 용량 RAM 배터리 256GB (대각선) 12GB 3300mAh 170.2mm\n","LACARE 610 87 .........\n","쿠키 사이드 테이블 42 xH870 030 W1196 ₩49,900\n","푸르밀 비타요구르트 65ml*20입 806371 340163 판매가: 2,700원\n","빙그레요구르트 65ml+20의 07 672092 판매가: 3,000원\n","동원/요쿠르트 65ml*5*3 801155 403225 판매가: 3,000원\n","바이오플레-플레인 150ml*8입 판매가 : 3,400원\n","2014코카콜라브라질 250ml 1,250 8801094623203 /E 코카콜라음료\n","동서)맥심모카라이트 20T 801037 067651 판매가: 4,400원\n","맥심슈프림골드 20입 01037 00304 판매가: 4,900원\n","맥스웰커피믹스 240g 80103 7 035650 판매가: 2,500원\n","빙)요플레복숭아 100g*4개 01104 240390 판매가: 3,750원\n","0 빙그레 기획 닥터캡슐사과 520ml / 10ml당 86원 4,500원\n","₩ 19,000 SIZE EUR 20/21 자율안전확인신고필증번호 BO44R1466-1170 제조년월: 16.12 03179354904 061 6561/1 H&M KR/S11 0461949 001\n","켈로그콘푸로스트 600g 801083001425 판매가: 3,950원\n","유기농 유기농 인증 유기농원유 70%, 가공유125\n","첵스초코(파우치팩) 1100g 01083 35110 판매가: 13,900원\n","일반냉장고 R-B432GCWP.AKOR LG전자 나노참숯탈취 크기(WxHxD) 멀티냉각방식 755x1777x707 특급냉장 Bar 핸들타입\n","M992GR NBPZAS107G OR (15)Gray 270 CE 259,000 용율 갑피 걸감1:천연가죽(돼지) 겉감2:합성가죽 걸감3:폴리에스터100% 창 폴리에스터 제조국 미국 제조원 New Balance Athletic Shoe. INC. 수입원 (주)이랜드월드 뉴발란스사업부 판매원 (주)이랜드월드 뉴발란스사업부 제조년월 2019.11 NBPZAS107G15270 NAME M992GR STYLE NBPZAS107G COLOR (15)Gray SIZE 270 PRICE 259,000 NBPZAS107G15270\n","특별기획 삼성 에어드레서(로즈골드) DF60N8500RG 02/01~02/11 [상품상세정보연결] · 3벌대 · 냄새분해 필터 · 사이즈: 445×1,850×615 mm · 공간제습 · 에너지효율: · 내부살균 롯데제휴카드 우리제휴카드 추가 하이마트 혜택 모델별 추가 카드 혜택 캐시백(금액대) 100,000 100,000 LPOINT 0 카드 · 캐시백(모델별) 0 0 롯데상품권 0기간 1~1 캐시백 0 2,129,000 롯데제휴카드 1.909.000 02/01~02/28 2,009,000 + 주가 청구할인 혜택 50,000 우리제휴카드 1.909.000 02/01~02/28 금액대별 혁택: 우리제휴카드 - 청 우리제휴 전월이용조건 중족시 최 행사모델 캐시백은 전산가 대비 구할인 대 월2만원 주가청구할인 50% 조과 결제시 적용\n","오뚜기)직접갈아먹는통후추50g 청정원 후추 100G 5,980 4,480 10G당 1,196원 10G당 448원 8801045450445 8801052204031\n","동서아몬드후레이크 620g 8801037 060737 판매가: 7,200원\n","등서 리츠이니언 73g / 10g당 226원 1,650 원\n"]}],"source":["for d in detections:\n","    print(' '.join(d))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9RdSQsOaKbZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}